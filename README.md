# ğŸ’  Infemeral

**Zero-Trust Distributed LLM Inference with Stateless Server Architecture**

[![Version](https://img.shields.io/badge/version-1.0.0-blue.svg)](https://github.com/infemeral/infemeral)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Python](https://img.shields.io/badge/python-3.11+-yellow.svg)](https://python.org)

> **The server provider is mathematically incapable of reconstructing your prompts or conversation history.**

Infemeral implements a **Split-Brain, Stateless Topology** that partitions LLM intelligence across three trust domains, ensuring that no single entity can access complete user data.

---

## ğŸ›ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER DEVICE (Trusted)                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Tokenizer  â”‚ â†’ â”‚  Embedder   â”‚ â†’ â”‚  DP Noise   â”‚ â†’ â”‚  Matrix M   â”‚ â”‚
â”‚  â”‚  (textâ†’ids) â”‚   â”‚  (idsâ†’vec)  â”‚   â”‚  (Îµ=2.0)    â”‚   â”‚  (rotation) â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â†‘                                                      â†“        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Decoder   â”‚ â† â”‚   LM Head   â”‚ â† â”‚  Matrix Mâ»Â¹ â”‚ â† â”‚ gRPC Client â”‚ â”‚
â”‚  â”‚  (idsâ†’text) â”‚   â”‚  (vecâ†’ids)  â”‚   â”‚  (inverse)  â”‚   â”‚  (TLS 1.3)  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚ cloaked vectors
                                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       RUNPOD L4 WORKER (Untrusted)                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    vLLM + PagedAttention                         â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚   â”‚
â”‚  â”‚  â”‚ Attn L1 â”‚ â†’ â”‚ FFN L1  â”‚ â†’ â”‚ Attn L2 â”‚ â†’ â”‚   ...   â”‚ â†’ Output â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â†‘ fetch encrypted KV           â†“ store encrypted KV             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚                    â”‚
                           â†“                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      REDIS SIDECAR (Encrypted State)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   AES-256-GCM Encrypted KV Cache   â”‚   TTL: 1hr   â”‚   LRU: 2GB  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Trust Domains

| Domain | Component | Holds | Cannot Access |
|--------|-----------|-------|---------------|
| **Sovereign Edge** | Client | Embedding layer, LM head, Matrix M | Nothing (fully trusted) |
| **Blind Core** | Server | Transformer blocks only | Raw embeddings, Matrix M |
| **Encrypted Locker** | Redis | AES-256-GCM encrypted KV | Unencrypted state |

---

## ğŸ” Security Properties

### Mathematical Guarantees

1. **Embedding Privacy**: The server only sees rotated vectors: `x' = Mx + noise`
   - Matrix M is orthogonal â†’ preserves dot products for attention
   - Differential privacy noise (Îµ=2.0, Î´=1e-5) prevents known-plaintext attacks

2. **Forward Secrecy**: Session keys rotate after every request
   - Compromise of current key doesn't expose past conversations
   - HKDF key derivation with fresh entropy

3. **State Confidentiality**: KV cache encrypted with AES-256-GCM
   - Redis sidecar never sees plaintext
   - Keys are session-specific and ephemeral

### What the Server Cannot Do

- âŒ Read your prompts or responses
- âŒ Reconstruct conversation history
- âŒ Correlate requests across sessions
- âŒ Access KV cache contents
- âŒ Derive the rotation matrix M

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- NVIDIA GPU with 24GB+ VRAM (L4, RTX 4090, A10G)
- Docker & Docker Compose
- NVIDIA Container Toolkit

### 1. Clone and Setup

```bash
git clone https://github.com/infemeral/infemeral.git
cd infemeral

# Install client dependencies
pip install -r requirements.client.txt

# Generate cryptographic keys
python scripts/generate_keys.py --output-dir ~/.infemeral/keys
```

### 2. Extract Embedding Weights

```bash
# Extract client-side weights from model
python scripts/extract_embeddings.py \
    --model meta-llama/Llama-3.1-8B-Instruct \
    --output ~/.infemeral/weights
```

### 3. Build Proto Files

```bash
chmod +x proto/build_proto.sh
./proto/build_proto.sh
```

### 4. Deploy Server

```bash
# Set your HuggingFace token for gated models
export HF_TOKEN=your_token_here

# Start production stack
docker compose -f docker-compose.prod.yml up -d

# Check server health
curl http://localhost:50051/health
```

### 5. Run Client

```bash
# Interactive mode
python -m client.main --server localhost:50051

# Single prompt
python -m client.main --server localhost:50051 \
    --prompt "Explain quantum computing in simple terms"
```

---

## â˜ï¸ RunPod Serverless Deployment

For cost-effective deployment with pay-per-request pricing, deploy to RunPod Serverless.

### 1. Build and Push Docker Image

```bash
# Build serverless image
docker build -f Dockerfile.serverless -t your-registry/infemeral/serverless:latest .

# Push to Docker Hub (or RunPod registry)
docker push your-registry/infemeral/serverless:latest
```

### 2. Create Network Volume

In the RunPod console:
1. Go to **Storage > Network Volumes**
2. Create a new volume (10GB minimum for Redis persistence)
3. Note the volume ID

### 3. Create Serverless Endpoint

In the RunPod console:
1. Go to **Serverless > Endpoints**
2. Click **New Endpoint**
3. Configure:
   - **Docker Image**: `your-registry/infemeral/serverless:latest`
   - **GPU**: NVIDIA L4 (24GB) recommended
   - **Environment Variables**:
     - `MODEL_NAME`: `meta-llama/Llama-3.1-8B-Instruct`
     - `HF_TOKEN`: Your HuggingFace token
   - **Network Volume**: Attach the volume created above
4. Deploy

### 4. Run Client (Serverless)

```bash
# Using HTTP transport with RunPod
python -m client.main \
    --transport http \
    --runpod-api-key YOUR_RUNPOD_API_KEY \
    --runpod-endpoint YOUR_ENDPOINT_ID \
    --prompt "Explain quantum computing"
```

### Serverless Configuration

See `runpod.toml` for detailed configuration options.

| Variable | Default | Description |
|----------|---------|-------------|
| `REDIS_EMBEDDED` | `true` | Run Redis as subprocess |
| `REDIS_DATA_PATH` | `/runpod-volume/redis-data` | Network volume path |
| `REDIS_ENABLE_PERSISTENCE` | `true` | Enable Redis persistence |
| `REDIS_MAX_MEMORY` | `2gb` | Redis memory limit |

### Cost Comparison

| Mode | Pricing | Best For |
|------|---------|----------|
| Docker Pod | ~$0.29/hour (L4) | Steady traffic, always-on |
| Serverless | ~$0.00024/second | Low traffic, pay-per-use |

---

## ğŸ“ Project Structure

```
infemeral/
â”œâ”€â”€ ğŸ“œ README.md                    # This file
â”œâ”€â”€ ğŸ“œ requirements.txt             # Server dependencies
â”œâ”€â”€ ğŸ“œ requirements.client.txt      # Client dependencies
â”œâ”€â”€ ğŸ“œ Dockerfile                   # Server container (gRPC)
â”œâ”€â”€ ğŸ“œ Dockerfile.serverless        # Serverless container (HTTP)
â”œâ”€â”€ ğŸ“œ Dockerfile.client            # Client container
â”œâ”€â”€ ğŸ“œ docker-compose.prod.yml      # Production deployment
â”œâ”€â”€ ğŸ“œ docker-compose.dev.yml       # Development setup
â”œâ”€â”€ ğŸ“œ runpod.toml                  # RunPod serverless config
â”‚
â”œâ”€â”€ ğŸ“‚ proto/                       # gRPC Contract
â”‚   â”œâ”€â”€ inference.proto             # Service & message definitions
â”‚   â””â”€â”€ build_proto.sh              # Stub generator script
â”‚
â”œâ”€â”€ ğŸ“‚ client/                      # Sovereign Edge (Trusted)
â”‚   â”œâ”€â”€ main.py                     # CLI entry point
â”‚   â”œâ”€â”€ ğŸ“‚ crypto/
â”‚   â”‚   â”œâ”€â”€ matrix.py               # Orthogonal rotation (M, Mâ»Â¹)
â”‚   â”‚   â”œâ”€â”€ noise.py                # Differential privacy
â”‚   â”‚   â””â”€â”€ keys.py                 # RSA & AES key management
â”‚   â”œâ”€â”€ ğŸ“‚ model/
â”‚   â”‚   â”œâ”€â”€ tokenizer.py            # HuggingFace tokenizer wrapper
â”‚   â”‚   â””â”€â”€ embedder.py             # Embedding & LM head layers
â”‚   â””â”€â”€ ğŸ“‚ transport/
â”‚       â”œâ”€â”€ grpc_client.py          # gRPC client (traditional)
â”‚       â””â”€â”€ http_client.py          # HTTP client (serverless)
â”‚
â”œâ”€â”€ ğŸ“‚ server/                      # Blind Core (Untrusted)
â”‚   â”œâ”€â”€ service.py                  # gRPC server implementation
â”‚   â”œâ”€â”€ handler.py                  # RunPod serverless handler
â”‚   â”œâ”€â”€ http_models.py              # HTTP request/response models
â”‚   â”œâ”€â”€ ğŸ“‚ engine/
â”‚   â”‚   â”œâ”€â”€ vllm_worker.py          # vLLM inference wrapper
â”‚   â”‚   â””â”€â”€ model_loader.py         # Headless model loading
â”‚   â”œâ”€â”€ ğŸ“‚ state/
â”‚   â”‚   â”œâ”€â”€ redis_connector.py      # Redis KV storage
â”‚   â”‚   â””â”€â”€ encryption.py           # KV cache encryption
â”‚   â””â”€â”€ ğŸ“‚ scripts/
â”‚       â””â”€â”€ start_redis.sh          # Redis startup for serverless
â”‚
â””â”€â”€ ğŸ“‚ scripts/                     # Utilities
    â”œâ”€â”€ generate_keys.py            # Key generation
    â”œâ”€â”€ extract_embeddings.py       # Weight extraction
    â””â”€â”€ benchmark.py                # Performance testing
```

---

## âš™ï¸ Configuration

### Client Configuration

```python
from client import InfemerSession

# Traditional gRPC deployment
session = InfemerSession(
    server_host="localhost",
    server_port=50051,
    model_name="meta-llama/Llama-3.1-8B-Instruct",
    embedding_dim=4096,
    privacy_epsilon=2.0,      # Lower = more private, more noise
    privacy_delta=1e-5,
    use_tls=True,
    key_dir=Path("~/.infemeral/keys"),
    transport="grpc",         # Use gRPC transport
)

# RunPod Serverless deployment
session = InfemerSession(
    model_name="meta-llama/Llama-3.1-8B-Instruct",
    embedding_dim=4096,
    privacy_epsilon=2.0,
    key_dir=Path("~/.infemeral/keys"),
    transport="http",                           # Use HTTP transport
    runpod_api_key="your_runpod_api_key",
    runpod_endpoint_id="your_endpoint_id",
)
```

### Server Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `MODEL_NAME` | `meta-llama/Llama-3.1-8B-Instruct` | Model to load |
| `HF_TOKEN` | - | HuggingFace API token |
| `REDIS_HOST` | `redis-sidecar` | Redis hostname |
| `REDIS_PORT` | `6379` | Redis port |
| `GPU_MEMORY_UTILIZATION` | `0.85` | vLLM GPU memory fraction |
| `MAX_MODEL_LEN` | `4096` | Maximum context length |

### Privacy Budget

```python
# Adjust privacy/utility tradeoff
privacy_epsilon = 2.0   # Standard: balanced privacy
privacy_epsilon = 1.0   # High privacy: more noise, less accuracy
privacy_epsilon = 4.0   # Low privacy: less noise, better accuracy
```

---

## ğŸ“Š Performance

### Benchmarks (Llama 3.1 8B on L4 24GB)

| Metric | Value |
|--------|-------|
| **Throughput** | 45 tokens/sec |
| **TTFT (Time to First Token)** | 180ms |
| **Matrix Rotation Overhead** | 2.3ms |
| **DP Noise Overhead** | 0.8ms |
| **gRPC Serialization** | 5.2ms (512 tokens) |
| **Total Privacy Overhead** | ~8ms/request |

### Memory Usage

| Component | Memory |
|-----------|--------|
| Rotation Matrix (4096Â²) | 64 MB |
| KV Cache (2048 tokens) | 512 MB |
| Embedding Weights | 1.5 GB |

Run benchmarks:
```bash
python scripts/benchmark.py --dim 4096 --seq-len 512
```

---

## ğŸ”¬ Technical Deep Dive

### Orthogonal Matrix Rotation

The security hinges on the server never learning the rotation matrix M.

```python
# Client-side
M = generate_orthogonal_matrix(dim=4096)  # M^T M = I
x_cloaked = (x + noise) @ M.T             # Rotate embedding

# Server-side (sees only x_cloaked)
# Attention: softmax((MQ)(MK)^T / âˆšd) = softmax(QK^T / âˆšd)
# Orthogonality preserves dot products!

# Client-side
x_output = x_cloaked_output @ M           # Inverse rotation
```

### Differential Privacy

Gaussian mechanism calibrated for Local DP:

```
Ïƒ = Î”f Â· âˆš(2ln(1.25/Î´)) / Îµ

Where:
- Î”f = L2 sensitivity (bounded by embedding norm)
- Îµ = privacy budget (lower = more private)
- Î´ = privacy failure probability
```

### Tide-Windowing

Context compression for long conversations:

```
[Attention Sinks (4 tokens)] + [Recent Context (2044 tokens)]
     â†“ preserved                    â†“ sliding window
```

---

## ğŸ›¡ï¸ Threat Model

### Adversary Capabilities

We assume the server operator:
- Has full access to server code and memory
- Can observe all network traffic (encrypted)
- Can modify server behavior (but client detects tampering)
- Can collude with Redis provider

### Mitigations

| Threat | Mitigation |
|--------|------------|
| **Embedding reconstruction** | Orthogonal rotation + DP noise |
| **Known-plaintext attack** | Differential privacy (Îµ, Î´) |
| **Session correlation** | Fresh rotation per session |
| **KV cache snooping** | AES-256-GCM encryption |
| **Key compromise** | Forward secrecy via rotation |
| **Model extraction** | Client holds embedding layers |

---

## ğŸ¤ Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

### Development Setup

```bash
# Clone repo
git clone https://github.com/infemeral/infemeral.git
cd infemeral

# Create virtual environment
python -m venv venv
source venv/bin/activate

# Install dev dependencies
pip install -r requirements.txt -r requirements.client.txt
pip install pytest black mypy

# Run tests
pytest tests/

# Format code
black client/ server/ scripts/
```

---

## ğŸ“œ License

MIT License - see [LICENSE](LICENSE) for details.

---

## ğŸ™ Acknowledgments

- [vLLM](https://github.com/vllm-project/vllm) - High-throughput inference
- [LMCache](https://github.com/LMCache/LMCache) - KV cache management
- [PySyft](https://github.com/OpenMined/PySyft) - Privacy-preserving ML inspiration
- [RunPod](https://runpod.io) - Serverless GPU infrastructure

---

<p align="center">
  <b>ğŸ’  Infemeral: Your thoughts, your control.</b>
</p>

